# app.py
import streamlit as st
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

st.set_page_config(page_title="äºŒæ¬¡å¯¾ç­–ï¼šç­”æ¡ˆã‚»ãƒ«ãƒ•æ¡ç‚¹MVP", layout="wide")

st.title("äºŒæ¬¡è©¦é¨“ãƒ»ç­”æ¡ˆã‚»ãƒ«ãƒ•æ¡ç‚¹ï¼ˆMVPï¼‰")
st.caption("å­¦ç¿’æ”¯æ´ç”¨ã€‚å®Ÿå¾—ç‚¹ãƒ»åˆå¦ã¯ä¿è¨¼ã—ã¾ã›ã‚“ã€‚")

with st.sidebar:
    st.header("å•é¡Œãƒ¡ã‚¿")
    year = st.selectbox("å¹´åº¦", ["R7(ä»®)", "R6", "R5", "R4", "ã‚«ã‚¹ã‚¿ãƒ "])
    jirei = st.selectbox("äº‹ä¾‹", ["â…  çµ„ç¹”äººäº‹", "â…¡ ãƒãƒ¼ã‚±", "â…¢ ç”Ÿç”£", "â…£ è²¡å‹™", "ã‚«ã‚¹ã‚¿ãƒ "])
    q = st.text_input("è¨­å•ï¼ˆä»»æ„ï¼‰", value="è¨­å•Xï¼šã€œã€œã«ã¤ã„ã¦ã€â€¦ã‚’è¿°ã¹ã‚ˆ")
    st.markdown("---")
    st.subheader("æ¡ç‚¹ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ï¼ˆé‡ã¿ï¼‰")
    w1 = st.slider("é¡Œæ„æ•´åˆ", 0.0, 1.0, 0.25)
    w2 = st.slider("è«–ç‚¹ã‚«ãƒãƒ¬ãƒƒã‚¸", 0.0, 1.0, 0.25)
    w3 = st.slider("æ ¹æ‹ ä¸€è²«æ€§", 0.0, 1.0, 0.20)
    w4 = st.slider("å…·ä½“æ€§", 0.0, 1.0, 0.15)
    w5 = st.slider("æ—¥æœ¬èª/æ§‹æˆ", 0.0, 1.0, 0.15)

st.subheader("æ¨™æº–è§£ï¼ˆçµ±åˆãƒ»å†æ§‹ç¯‰ç‰ˆï¼‰")
std_answer = st.text_area(
    "â€»å„æ ¡ã®æ¨¡ç¯„è§£ç­”ã®è»¢è¼‰ã¯é¿ã‘ã€ã‚ãªãŸãŒè¦ç´„ã—ãŸâ€œæ¨™æº–è§£â€ã‚’è²¼ã‚‹",
    height=180,
    placeholder="ä¾‹ï¼‰ä¸ä»¶ã®å¼·ã¿A/åˆ¶ç´„Bã«åŸºã¥ãã€æ–½ç­–â‘ â€¦â‘¡â€¦ï¼ˆåŠ¹æœï¼šâ€¦ã€æ¡ä»¶ï¼šâ€¦ï¼‰"
)

st.subheader("ã‚ãªãŸã®ç­”æ¡ˆ")
user_answer = st.text_area(
    "ç­”æ¡ˆã‚’è²¼ã‚Šä»˜ã‘",
    height=220,
    placeholder="ï¼ˆã“ã“ã«è‡ªåˆ†ã®è§£ç­”ã‚’è²¼ã‚‹ï¼‰"
)

# é‡è¦èªå¥ã®æŠ½å‡ºï¼ˆç°¡æ˜“ï¼‰ï¼šæ¨™æº–è§£ã‹ã‚‰åè©ã£ã½ã„ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ‰‹å‹•å…¥åŠ›ã§ãã‚‹æ¬„ã‚‚ç”¨æ„
st.markdown("### é‡è¦èªå¥ï¼ˆä»»æ„ãƒ»ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ¤å®šã«ä½¿ç”¨ï¼‰")
key_phrases_raw = st.text_input(
    "ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼ˆä¾‹ï¼šåœ¨åº«ç®¡ç†, éƒ¨é–€é–“é€£æº, æ¨™æº–åŒ–, æŒ‡å°ä½“åˆ¶ï¼‰", value=""
)
key_phrases = [k.strip() for k in key_phrases_raw.split(",") if k.strip()]

def tfidf_similarity(a: str, b: str) -> float:
    if not a.strip() or not b.strip():
        return 0.0
    vec = TfidfVectorizer(min_df=1, ngram_range=(1,2))
    X = vec.fit_transform([a, b])
    v0, v1 = X[0].toarray(), X[1].toarray()
    num = (v0 * v1).sum()
    den = np.linalg.norm(v0) * np.linalg.norm(v1)
    return float(num/den) if den != 0 else 0.0

def coverage_score(keys, text):
    if not keys:
        return 0.5  # ã‚­ãƒ¼æœªè¨­å®šãªã‚‰ä¸­ç«‹å€¤
    hit = sum(1 for k in keys if k in text)
    return hit / len(keys)

def specificity_score(text):
    # ã–ã£ãã‚Šï¼šæ•°å­—ãƒ»å›ºæœ‰åè©ãƒ»æ¡ä»¶èªãŒå¤šã„ã»ã©é«˜ã
    cues = ["ï¼…","%","ä»¶","å††","æ—¥","é€±","æœˆ","å‰å¹´æ¯”","åœ¨åº«","KPI","ROI","CV","NPV","å›è»¢","ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ","æ¡ä»¶","åŠ¹æœ","ç›®çš„","æ•°å€¤","æŒ‡æ¨™"]
    hit = sum(text.count(c) for c in cues)
    L = max(len(text), 1)
    return min(1.0, hit / (L/80))  # ãƒ†ã‚­ãƒˆãƒ¼æ­£è¦åŒ–

def structure_score(text):
    # ç®‡æ¡æ›¸ããƒ»æ¥ç¶šè©ã§åŠ ç‚¹
    cues = ["â‘ ","â‘¡","â‘¢","ãƒ»","â– ","â—†","ã¾ãš","æ¬¡ã«","ä¸€æ–¹","ã—ãŸãŒã£ã¦","çµæœã¨ã—ã¦","ç†ç”±ã¯","æ ¹æ‹ ã¯"]
    hit = sum(text.count(c) for c in cues)
    L = max(len(text), 1)
    return min(1.0, (0.2 + hit / (L/100)))

def reasoning_consistency(std, usr):
    # TF-IDFé¡ä¼¼ã§ä»£ç”¨ï¼ˆä¸ä»¶æ•´åˆã¯æœ¬æ¥ä¸ä»¶ãƒ†ã‚­ã‚¹ãƒˆã‚‚å¿…è¦ï¼‰
    return tfidf_similarity(std, usr)

def headline_scores(std, usr, keys):
    s1 = tfidf_similarity(std, usr)           # é¡Œæ„æ•´åˆï¼ˆç°¡æ˜“ä»£æ›¿ï¼‰
    s2 = coverage_score(keys, usr)            # è«–ç‚¹ã‚«ãƒãƒ¬ãƒƒã‚¸
    s3 = reasoning_consistency(std, usr)      # æ ¹æ‹ ä¸€è²«æ€§ï¼ˆç°¡æ˜“ï¼‰
    s4 = specificity_score(usr)               # å…·ä½“æ€§
    s5 = structure_score(usr)                 # æ—¥æœ¬èª/æ§‹æˆ
    return s1, s2, s3, s4, s5

col1, col2 = st.columns(2)
if st.button("æ¡ç‚¹ã™ã‚‹", type="primary", use_container_width=True):
    s1, s2, s3, s4, s5 = headline_scores(std_answer, user_answer, key_phrases)
    total = (w1*s1 + w2*s2 + w3*s3 + w4*s4 + w5*s5) / max(w1+w2+w3+w4+w5, 1e-9)
    with col1:
        st.metric("ç·åˆã‚¹ã‚³ã‚¢ï¼ˆ0ã€œ1ï¼‰", f"{total:.2f}")
        st.progress(total)
    with col2:
        st.write("**å†…è¨³**")
        st.write(f"- é¡Œæ„æ•´åˆï¼ˆTF-IDFé¡ä¼¼ï¼‰: {s1:.2f}")
        st.write(f"- è«–ç‚¹ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆé‡è¦èªå¥ãƒ’ãƒƒãƒˆç‡ï¼‰: {s2:.2f}")
        st.write(f"- æ ¹æ‹ ä¸€è²«æ€§ï¼ˆç°¡æ˜“ï¼‰: {s3:.2f}")
        st.write(f"- å…·ä½“æ€§ï¼ˆæ•°å€¤/æ¡ä»¶ã®æ‰‹ãŒã‹ã‚Šï¼‰: {s4:.2f}")
        st.write(f"- æ—¥æœ¬èª/æ§‹æˆï¼ˆç®‡æ¡æ›¸ããƒ»æ¥ç¶šè©ï¼‰: {s5:.2f}")

    # é‡è¦èªå¥ã®ãƒ’ãƒƒãƒˆ/æœªãƒ’ãƒƒãƒˆã‚’å¯è¦–åŒ–
    if key_phrases:
        st.markdown("### é‡è¦èªå¥ã®ãƒ’ãƒƒãƒˆçŠ¶æ³")
        hits = [k for k in key_phrases if k in user_answer]
        misses = [k for k in key_phrases if k not in user_answer]
        st.success("ğŸŸ¢ ãƒ’ãƒƒãƒˆ: " + (", ".join(hits) if hits else "ãªã—"))
        st.error("ğŸ”´ æœªãƒ’ãƒƒãƒˆ: " + (", ".join(misses) if misses else "ãªã—"))

st.markdown("---")
st.caption("Â© å­¦ç¿’æ”¯æ´MVP / äºŒæ¬¡ã®å®Ÿå¾—ç‚¹ã¯å…¬è¡¨æ¡ç‚¹ã®ã¿ãŒæ­£ã§ã™ã€‚æ¨™æº–è§£ã¯è‘—ä½œæ¨©é…æ…®ã®ãŸã‚å†æ§‹ç¯‰ç‰ˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
